---
title: "Divide & Conquer + Dynamic Programming"
description: "A survey of concepts and interactive visualizations from Part 1 of my Graduate Algorithms course"
date: "2026-02-19"
# updated: '2026-10-20'
status: "in-progress"
type: "retro"
tags: ["algorithms", "computer-science", "MSCS"]
# category: ['projects']
draft: true
audience: "All"
media_subpath: "/ideas/ga-1/"
# parent: '2025/dl-retro'
image:
  # path: "hero-clipart-blume-vintage-kunst-1631264278ngu.png"
  # path: "hero-backprop.png"
  path: "hero2.jpg"
  alt: "Green ripples abstract art"
  # maxWidth: "800px"
hideCaption: true
---

import BookCard from "../../../../components/BookCard.astro";
import MasterTheoremViz from "../../../../components/ideas/ga-1/MasterTheoremViz.jsx";
import DPDagVisualizer from "../../../../components/ideas/ga-1/DPDagVisualizer.jsx";
import algsDpvImg from "../../../books/algs-dpv.jpg";

## Introduction

This piece serves as both a personal study guide and a technical reference. I am currently taking Georgia Tech's [CS 6515: Intro to Graduate Algorithms](https://omscs.gatech.edu/cs-6515-intro-graduate-algorithms) in the Spring 2026 semester. I'm organizing these notes to consolidate my learning for Exam 1—following the Feynman technique of teaching to understand, while also sharing insights for those interested in the course or my background. My audience includes prospective OMSCS students, potential employers, and colleagues seeking to understand the course content and my current knowledge (along with what I still need to learn).

Writing this kind of reflection involves balancing honesty about my learning journey and the extent of my understanding with the recognition that I'm still developing expertise. This course is notoriously demanding, and this write-up represents my attempt to process the material and build intuition under time pressure. The bulk of this article captures my study notes, alongside two interactive tools I built to visualize the core concepts.

### TL;DR

- **Audience**: Prospective OMSCS students, colleagues, and hiring managers.
- **Scope**: Study notes covering Divide & Conquer (Master Theorem) and Dynamic Programming (DAG patterns).
- **Takeaways**: Understand recursive algorithmic patterns, formulate DP recurrences, and map abstract concepts to visual representations.
- **Extras**: Interactive Master Theorem visualizer and DP DAG visualizer.

## Divide & Conquer

Use this to map a recurrence to Master Theorem behavior and see which level dominates work as parameters change.

### Solution Format

The course encourages structuring problem-solving into distinct sections rather than diving straight into code. This approach builds a habit of thinking algorithmically and mathematically. _Note: Correctness is never assumed from the algorithm steps; it must be explicitly argued._

- **(a) Algorithm Description:** Explain _how_ your algorithm solves the problem using a plain-English narrative. You can use paragraphs or high-level bullet points, but **pseudocode is strictly forbidden**.
  - Avoid writing code disguised as words (e.g., translating a script line-by-line). Deeply nested bullet points are usually a red flag that you are doing this.
  - Walk through every major step, ending with the final return statement.
  - If you are adapting a known algorithm, explicitly highlight the modifications you made.
- **(b) Justification of Correctness:** Explain _why_ your algorithm works.
  - Write a narrative, informal justification (no formal mathematical or inductive proofs are required).
  - If you modified a known algorithm, you must explain why your specific tweaks are correct and successfully solve the problem.
- **(c) Runtime Analysis:** Analyze your algorithm using worst-case **Big-O notation**.
  - You can skip analyzing $O(1)$ operations.
  - You may assert the standard runtime of unmodified "black-box" algorithms without extra proof.
  - If you modify a black box, you must justify how those changes impact the runtime—even if the overall Big-O doesn't change.
  - Always conclude with a single, fully simplified final runtime in Big-O notation.

---

### Guide to finding a D&C solution

Follow this workflow to brainstorm and write your solution:

1. **Identify the Pattern:** Determine if your problem maps to a standard algorithm.
   - _Sorted data_ usually points to Binary Search.
   - _Unsorted data_ usually points to Merge Sort or FastSelect.
   - _Polynomials, convolution, or multiplication_ usually point to Fast Fourier Transform (FFT). For integer multiplication specifically, Karatsuba's algorithm is a classic approach ($O(n^{\log_2 3})$).
2. **Define Modifications (If Any):** Decide if you can use the known algorithm "as is" or if it needs tweaking. If you tweak it, clearly outline what steps, inputs, or outputs are changing.
3. **Draft the Steps:** Write out the algorithm's execution in clear words. Make sure to define your base cases (if needed) and ensure your algorithm ultimately returns exactly what the prompt asks for.
4. **Draft the Proof of Correctness:** Write out your informal proof. To build a strong justification, answer questions like:
   - _Why is this specific black box suited for this input data?_
   - _Why did you make those specific modifications?_
   - _Why are we guaranteed that the problem space shrinks on each round?_
   - _Why are the base cases logically sound?_
   - _What is the logic behind branching left or right on each recursive call?_
5. **Calculate the Runtime:** Step through your algorithm to build your final worst-case Big-O analysis.

### Example Walkthrough: Majority Element

Let's walk through a concrete example.

**Problem Statement:** An array `A[1…n]` has a majority element if more than half its entries are the same. Given an array, design an $O(n \log n)$ algorithm to determine if it has a majority element, and if so, find it. The elements are not sortable (e.g., GIF files), so you can only test for equality `A[i] == A[j]` in $O(1)$ time.

**Algorithm:**
1. Recursively divide the input array into two equal-sized subarrays, $A_1$ and $A_2$.
2. **Base case:** If the subarray has size 1, report its single element as the majority element.
3. At each level of recursion, check the majority element returned by the left and right subarrays.
4. For each potential majority element, scan the combined array to count its occurrences.
5. If one element occurs strictly more than $n/2$ times in the combined array, return it as the majority element.
6. Otherwise, return `NO_MAJORITY`.

**Justification of Correctness:**
If a majority element exists in the combined array, it *must* also be the majority element in at least one of its two halves. By recursively dividing the input space, we ensure that if a true majority element exists, it will emerge as a candidate from the base cases up through the recursion. Counting occurrences at each level guarantees we only promote elements that are genuine majorities for the specific subarray being considered.

**Runtime Analysis:**
- We split the problem into 2 subproblems: $a = 2$.
- Each subproblem is exactly half the size: $b = 2$.
- The work to combine results (scanning the array to count occurrences) takes linear time: $O(n^1)$, so $d = 1$.
- We have the recurrence $T(n) = 2T(n/2) + O(n)$.
- Since $\log_b(a) = \log_2(2) = 1$, and $d = 1$, we are in **Case 2 (Balanced)**.
- The overall runtime is $O(n^1 \log n) \implies O(n \log n)$.

### Master Theorem

For some constants $a > 0$, $b > 1$, and $d \geq 0$,
where:
$a$ - number of subproblems
$b$ - is the factor by which the input size shrinks
$d$ - is the exponent of the work done at each level of recursion (so combining costs $O(n^d)$)

$$
T(n) = \underbrace{aT (n/b)}_{\text{recursive branching}} + \underbrace{O(n^d)}_{\text{local work (root)}}
$$

$$
T(n) =
\begin{cases}
\Theta(n^{\log_b(a)}) &\text{if } n^{\log_b(a)} > n^d \quad\text{ ``leaf heavy"} \\
\Theta(n^d \log(n)) &\text{if } n^{\log_b(a)} = n^d \quad\text{ ``balanced"}\\
\Theta(n^d) &\text{if } n^{\log_b(a)} < n^d \quad\text{ ``root heavy"} \\
\end{cases}
$$

- **Case 1 (Leaf-Heavy):** $n^{\log_b​(a)} > n^d$. The recursive branching explodes, meaning the vast majority of the work happens at the bottom of the tree. The leaves win, so the bound is strictly the number of leaves: $\Theta(n^{\log_b​(a)})$.

- **Case 2 (Perfectly Balanced):** $n^{\log_b​(a)} = n^d$. It is a tie. The local work at the root matches the work at the leaves, and the work across every internal level of the tree is identical. Because the work per level is constant, you just multiply the root work by the number of levels ($\log n$). The bound is: $\Theta(n^d\log n)$. _(Note: The "extended" Case 2 handles $f(n) = \Theta(n^{\log_b a} \log^k n)$, resulting in $\Theta(n^{\log_b a} \log^{k+1} n)$)._
- **Case 3 (Root-Heavy):** $n^{\log_b​(a)} < n^d$. The local work dwarfs the branching. The work shrinks geometrically as you go down the tree, meaning the total time is dominated by the massive chunk of work done at the very beginning. The root wins, so the bound is strictly the root work: $\Theta(n^d)$.

### Divide & Conquer Visualization

Drag the $a, b,$ and $d$ sliders below to see how the recursion tree shifts between the three Master Theorem cases.

<div class="viz-shell">
  <MasterTheoremViz client:visible />
</div>

### Work per level

1. **Number of nodes:** At level $k$, the tree has branched $k$ times, so there are $a^k$ nodes.
2. **Size of each subproblem:** The problem size $n$ has been divided by $b$ exactly $k$ times, making the input size for each node $n/b^k$.
3. **Work per node:** Since the local work is bounded by $O(\text{size}^d)$, the work at a single node on level $k$ is $(\frac{n}{b^k}​)^d$, which simplifies to $\frac{n^d}{b^{kd}}​$.

If you multiply the **number of nodes** by the **work per node**, you get the total work for the entire $k$-th level:

$$
a^k \times \frac{n^d​}{b^{kd}}
$$

Pull out the $n^d$ (which is the work at the root), and group the $k$ exponents together, and you get the formula for the total work done at the $k$-th level of the tree:

$$
O(n^d) \times \left(\frac{a}{b^d}\right)^k
$$

The Master Theorem uses $\log_b​(a)$ instead of just comparing $a$ to $b^d$. It is just a logarithmic algebraic rewrite of the exact same inequality!

If you take $a=b^d$ and take the $\log_b$​ of both sides, you get:

$$
\log_b​(a)=\log_b​(b^d)
$$

$$
\log_b​(a)=d
$$

So, comparing $\log_b​(a)$ to $d$ is mathematically identical to comparing the branching factor $a$ to the work-shrinkage factor $b^d$.

### What to remember

- **Problem Structure**: Always define the algorithm steps, provide an informal justification of correctness based on why the problem space shrinks and the base cases hold, and finish with a single Big-O limit.
- **Master Theorem Formula**: $T(n) = aT(n/b) + O(n^d)$
- **Master Theorem Cases**:
  - $d > \log_b(a)$: Root-heavy $\to O(n^d)$ (combine step dominates).
  - $d = \log_b(a)$: Balanced $\to O(n^d \log n)$ (work is spread evenly).
  - $d < \log_b(a)$: Leaf-heavy $\to O(n^{\log_b a})$ (recursive calls dominate).

## Dynamic Programming

Use this to inspect how different DP families map to DAG shapes, transitions, and extraction paths.

### Explaining Your Approach

I've learned that a rigorous Dynamic Programming solution is best communicated through four key components. Skipping straight to code often masks underlying logical flaws; writing these out forces you to fully understand the state space.

**(a) Subproblem Definition.** Define the state, like $T(i)$ or $T(i,j)$, purely in words. State clearly what subset of the input it operates on and whether it mandates including a specific element (e.g., "ending at index $i$"). 

**(b) Recurrence.** Write the transition purely in mathematical notation. A complete recurrence must cover:
- All recursive step cases.
- All necessary base cases.
- Explicit bounds for all variables.

**(c) Implementation Analysis.** To prove the algorithm is efficient and complete, outline:
1. **State Space:** The total number of subproblems in Big-O.
2. **Transition Time:** The runtime to calculate one subproblem, which dictates the total time to fill the table.
3. **Extraction:** Where and how to extract the final answer from the table.
4. **Extraction Time:** The runtime of the extraction step.

> [!note]
> **On Extraction:** Just finding the optimal numeric value is often not enough. If a problem asks for the optimal sequence or path, you must trace back through the table/DAG to reconstruct your choices. This typically takes $O(n)$ or time proportional to the path length.

> [!tip]
> **Implementation Rules of Thumb:** Try to formulate DP as iterative, bottom-up table fills rather than top-down recursion with memoization. Think of the inputs as immutable, and map your base cases starting from index $0$ or $-1$ if necessary to avoid out-of-bounds edge cases.

### Problem-Solving Heuristics

**1. What is the topology?** Is the input a 1D array, a pair of strings, items with weights, an interval, a tree, or a set of elements?

**2. What are you optimizing?** Max/min value? Count of ways? Length of a subsequence?

**3. What constraint distinguishes the flavor?** Must be contiguous (Kadane) vs. no-adjacent (Robber) vs. any subsequence (LIS)? Match-based (LCS) vs. cost-based (Edit Dist)? Items used once (0/1) vs. unlimited (Unbounded)?

**4. Write the subproblem in words first.** This is the most important step. The recurrence follows naturally from a correct subproblem definition.

**5. Always define base cases.** Ensure every referenced table entry is well-defined. If T(i) references T(i-2), define T(0) and possibly T(-1).

**6. Provide bounds for all variables.** Every variable in the recurrence must have explicit bounds (e.g., "for 1 ≤ i ≤ n").



<style>
  {`
    /* Allow math blocks to scroll horizontally if they overflow */
    .katex-display {
      overflow-x: auto;
      overflow-y: hidden;
      padding-top: 0.5em;
      padding-bottom: 0.5em;
    }
    
    .viz-shell {

      grid-column: 1 / 4 !important;
      position: relative;
      z-index: 1;
      isolation: isolate;
      width: 100%;
      max-width: 1600px;
      margin: 1rem auto 2rem;
      overflow-x: auto;
    }
  `}
</style>

### Pattern A: Linear (1D Chain)

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="A" />
</div>

The topology is a 1D array. The flavor depends on how far back you look and what you accumulate.

#### Flavor 1: "Look-Back-One" (Contiguous / Kadane's Style)

**Concept:** _You must extend the immediately preceding subproblem, or start completely over. The current element must be included._

**(a) Subproblem:** T(i) = maximum sum of a contiguous subarray of A[1..i] which includes A[i].

**(b) Recurrence:**

**Base Cases:**

$$
T(1) = A[1]
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= \max( A[i],  T(i-1) + A[i] ) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _Interpretation: either start a new subarray at A[i], or extend the best subarray ending at A[i-1]._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max{ T(i) : 1 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

#### Flavor 2: "Look-Back-Two" (Skip / House Robber Style)

**Concept:** _Adjacent elements cannot both be selected. Decide whether to take the current element (skip previous) or leave it (keep previous optimal). The current element need not be included._

**(a) Subproblem:** T(i) = maximum sum obtainable from A[1..i] (A[i] may or may not be selected).

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0) &= 0 \\
T(1) &= A[1]
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= \max( T(i-1),  T(i-2) + A[i] ) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _T(i-1) = skip A[i]; T(i-2) + A[i] = take A[i] and skip A[i-1]._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `T(n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Look-Back-All" (Subsequence / LIS Style)

**Concept:** _The sequence need not be contiguous. Scan all previous valid subproblems to find the best predecessor. The current element must be included._

**(a) Subproblem:** T(i) = length of the longest increasing subsequence of A[1..i] which includes A[i].

**(b) Recurrence:**

**Base Cases:**

$$
T(1) = 1
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= 1 + \max \big( \{0\} \cup \{ T(j) : \\
     &\quad 1 \le j < i,\; A[j] < A[i] \} \big) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _If no j satisfies A[j] < A[i], the max is taken over {0} (set containing zero), so T(i) = 1._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n²)`
- **(3) Return:** `max{ T(i) : 1 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

### Pattern B: Grid (2D / Strings)

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="B" />
</div>

The topology is the (i-1, j), (i, j-1), (i-1, j-1) neighborhood. The flavor depends on whether you match elements or accumulate path costs.

#### Flavor 1: "Match or Drop" (Longest Common Subsequence)

**Concept:** _If elements match, gain 1 and consume both. If not, drop one element from either sequence and take the best._

**(a) Subproblem:** T(i,j) = length of the LCS of A[1..i] and B[1..j].

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,j) &= 0 \quad \text{for } 0 \le j \le m \\
T(i,0) &= 0 \quad \text{for } 0 \le i \le n
\end{align*}
$$

**Recursive Step:**

$$
T(i,j) =
\begin{aligned}
&\begin{cases}
T(i-1,j-1) + 1 & \text{if } A[i] = B[j] \\
\max( T(i-1,j),  T(i,j-1) ) & \text{if } A[i] \ne B[j]
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 1 \le j \le m
\end{aligned}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Penalty Cost" (Edit Distance)

**Concept:** _Transform A into B. Every mismatch incurs a cost; take the minimum of substitution, deletion, or insertion._

**(a) Subproblem:** T(i,j) = minimum edit distance to transform A[1..i] into B[1..j].

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,j) &= j \quad \text{for } 0 \le j \le m \quad (\text{insert } j \text{ characters}) \\
T(i,0) &= i \quad \text{for } 0 \le i \le n \quad (\text{delete } i \text{ characters})
\end{align*}
$$

**Recursive Step:**

$$
T(i,j) =
\begin{cases}
T(i-1,j-1) & \text{if } A[i] = B[j] \\
1 + \min\big( T(i-1,j-1), \\
\quad T(i-1,j), T(i,j-1) \big) & \text{if } A[i] \ne B[j]
\end{cases}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Path Accumulation" (Min Path Sum)

**Concept:** _Move through a physical grid accumulating weights. No matching — just movement constraints (right or down)._

**(a) Subproblem:** T(i,j) = minimum cost to reach cell (i,j) from cell (1,1).

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(1,1) &= C[1][1] \\
T(i,1) &= T(i-1,1) + C[i][1] \quad \text{for } 2 \le i \le n \\
T(1,j) &= T(1,j-1) + C[1][j] \quad \text{for } 2 \le j \le m
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= C[i][j] + \min( T(i-1,j), T(i,j-1) ) \\
       &\quad \text{for } 2 \le i \le n, 2 \le j \le m
\end{aligned}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

### Pattern C: Knapsack

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="C" />
</div>

The topology involves jumping leftwards across a capacity dimension. The flavor changes based on whether items are unique, reusable, or you are counting combinations.

#### Flavor 1: "Take It or Leave It" (0/1 Knapsack)

**Concept:** _Each item can only be used once. You transition from the previous row (i-1)._

**(a) Subproblem:** T(i,w) = maximum value achievable using items from {1..i} with capacity w.

**(b) Recurrence:**

**Base Cases:**

$$
T(0,w) = 0 \quad \text{for } 0 \le w \le W
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,w) &= \begin{cases}
T(i-1,w) & \text{if } w_i > w \\
\max( T(i-1,w),  T(i-1, w-w_i) + v_i ) & \text{if } w_i \le w
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 0 \le w \le W
\end{aligned}
$$

> [!note]
> _wᵢ and vᵢ are the weight and value of item i._

**(c) Analysis:**

- **(1) Subproblems:** `O(n·W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(n,W)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Infinite Reuse" (Unbounded Knapsack / Min Coin Change)

**Concept:** _If you take an item, you can take it again. You transition from the current row (i), not (i-1). Shown here as Minimum Coin Change._

**(a) Subproblem:** T(j) = minimum number of coins needed to make change for amount j, using coins from the given denominations.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0) &= 0 \\
T(j) &= \infty \quad \text{if no coin } \le j
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(j) &= 1 + \min_{ \substack{1 \le i \le n\\c_i \le j} } \{ T(j - c_i) \} \\
     &\quad \text{for } 1 \le j \le W
\end{aligned}
$$

> [!note]
> _Can also be written as 2D: T(i,w) = min( T(i-1,w), T(i, w-cᵢ) + 1 ), where row i means "using coins 1..i" and staying in row i allows reuse._

**(c) Analysis:**

- **(1) Subproblems:** `O(W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(W)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Counting Combinations" (Subset Sum / Coin Change 2)

**Concept:** _You are not maximizing value — you are summing all possible ways to reach a state. Replace max with +._

**(a) Subproblem:** T(i,w) = number of ways to form amount w using coins from {1..i}.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,0) &= 1 \\
T(0,w) &= 0 \quad \text{for } 1 \le w \le W
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,w) &= \begin{cases}
T(i-1,w) & \text{if } c_i > w \\
T(i-1,w) + T(i, w-c_i) & \text{if } c_i \le w
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 0 \le w \le W
\end{aligned}
$$

> [!note]
> _Staying in row i (for the cᵢ ≤ w case) allows reuse of coin i. Moving to row i-1 only would give 0/1 counting._

**(c) Analysis:**

- **(1) Subproblems:** `O(n·W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(n,W)`
- **(4) Return time:** `O(1)`

---

### Pattern D: Interval (Pyramid)

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="D" />
</div>

The topology always merges sub-intervals. The flavor depends on whether you split at an arbitrary k, shrink from edges, or pivot on the last action.

#### Flavor 1: "The K-Split" (Matrix Chain Multiplication / Optimal BST)

**Concept:** _The cost of interval (i,j) depends on splitting it into (i,k) and (k+1,j) plus the cost to merge._

**(a) Subproblem:** T(i,j) = minimum cost to multiply matrices Aᵢ through Aⱼ. (Matrix Aᵢ has dimensions p[i-1] × p[i].)

**(b) Recurrence:**

**Base Cases:**

$$
T(i,i) = 0 \quad \text{for } 1 \le i \le n
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \min_{ i \le k \le j-1} \{ T(i,k) + T(k+1,j) + p[i-1] \cdot p[k] \cdot p[j] \} \\
       &\quad \text{for } 1 \le i < j \le n
\end{aligned}
$$

> [!note]
> _Fill order: by increasing interval length ℓ = j - i, from ℓ=1 up to ℓ=n-1._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n³)`
- **(3) Return:** `T(1,n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Shrink from Edges" (Longest Palindromic Subsequence)

**Concept:** _No k-loop needed. Compare the two outermost elements. If they match, the interval shrinks by 2. If not, shrink by 1 from either side._

**(a) Subproblem:** T(i,j) = length of the longest palindromic subsequence of A[i..j].

**(b) Recurrence:**

**Base Cases:**

$$
T(i,i) = 1 \quad \text{for } 1 \le i \le n
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \begin{cases}
T(i+1,j-1) + 2 & \text{if } A[i] = A[j] \\
\max( T(i+1,j),  T(i,j-1) ) & \text{if } A[i] \ne A[j]
\end{cases} \\
&\quad \text{for } 1 \le i < j \le n
\end{aligned}
$$

> [!note]
> _Base case T(i,i+1): if A[i]=A[i+1] then 2, else 1. This is handled by the recurrence if you define T(i,i-1)=0 for empty intervals._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n²)`
- **(3) Return:** `T(1,n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "The Last Action" (Burst Balloons)

**Concept:** _Instead of the first split, think about k as the last balloon popped in interval (i,j). This makes left and right subproblems independent._

**(a) Subproblem:** T(i,j) = maximum coins from bursting all balloons in the open interval (i,j), where i and j are unpopped boundary balloons.

**(b) Recurrence:**

**Base Cases:**

$$
T(i,j) = 0 \quad \text{if } j = i+1 \quad (\text{no balloons between})
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \max_{i < k < j} \{ T(i,k) + T(k,j) + A[i] \cdot A[k] \cdot A[j]\} \\
       &\quad \text{for } 0 \le i < j \le n+1
\end{aligned}
$$

> [!note]
> _Boundaries A[0] and A[n+1] are sentinel values = 1. The key insight: choosing k last means the left/right subproblems don't interfere._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n³)`
- **(3) Return:** `T(0, n+1)`
- **(4) Return time:** `O(1)`

---

### Pattern E: Tree DP

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="E" />
</div>

Tree DP requires defining multiple states per node to handle inclusion/exclusion constraints. Fill order is post-order (leaves first, root last).

#### Flavor 1: "Independent Set" (Max Weight Independent Set / House Robber III)

**Concept:** _You cannot select a node and its direct children. Two states per node: exclude or include._

**(a) Subproblem:** T(u,0) = max weight of an independent set in the subtree rooted at u, excluding u. T(u,1) = same, including u.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(u,0) &= 0 \\
T(u,1) &= w(u)
\end{align*}
\quad \text{for leaf node } u
$$

**Recursive Step:**

$$
\begin{align*}
T(u,0) &= \sum \max( T(v,0), T(v,1) ) \\
       &\quad \text{over all children } v \text{ of } u \\
T(u,1) &= w(u) + \sum T(v,0) \\
       &\quad \text{over all children } v \text{ of } u
\end{align*}
$$

> [!note]
> _When u is excluded, each child is free to be included or not. When u is included, all children must be excluded._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)  (2 states per node)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max( T(root,0), T(root,1) )`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Path Tracking" (Diameter of a Tree)

**Concept:** _The longest path may arch over a node. T(u) tracks the longest straight path down from u; a secondary equation tracks the arch._

**(a) Subproblem:** T(u) = length of the longest path starting at u and going downward into the subtree of u.

**(b) Recurrence:**

**Base Cases:**

$$
T(u) = 1 \quad \text{for leaf node } u
$$

**Recursive Step:**

$$
\begin{aligned}
T(u) &= 1 + \max \{ T(v) : v \text{ is a child of } u \} \\
     &\quad (\text{longest arm in nodes})
\end{aligned}
$$

To extract the exact answer for the diameter:

$$
\begin{aligned}
&\text{Diameter through } u = T(v_1) + T(v_2) + 1 \\
&\quad (\text{where } v_1, v_2 \text{ are children with largest } T)
\end{aligned}
$$

$$
\text{Answer} =
\begin{cases}
\max_u \{ \text{diameter through } u \} - 1 & (\text{if asking for edges}) \\
\max_u \{ \text{diameter through } u \} & (\text{if asking for nodes})
\end{cases}
$$

> [!note]
> _If u has ≤1 child, diameter through u is just T(u). Track the global max during the fill pass._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max over all u of (top two T(child) values summed)`
- **(4) Return time:** `O(n)`

---

### Pattern F: Bitmask (Subset DP)

<div class="viz-shell">
  <DPDagVisualizer client:visible pattern="F" />
</div>

Bitmasks track which elements have been visited/used. Subsets are encoded as integers where bit i indicates element i is in the set. The flavor changes based on whether you care about the ending node or just the groups formed.

#### Flavor 1: "Path Building" (Traveling Salesperson Problem)

**Concept:** _You need to know which cities S you have visited AND which city i you are currently at, so you can extend to the next city j._

**(a) Subproblem:** T(S,i) = minimum cost to visit exactly the cities in set S, starting from city 1 and ending at city i, where i ∈ S.

**(b) Recurrence:**

**Base Cases:**

$$
T(\{1\}, 1) = 0
$$

**Recursive Step:**

$$
\begin{aligned}
T(S, i) &= \min_{j \in S\setminus\{i\}} \{ T(S\setminus\{i\}, j) + d(j,i) \} \\
        &\quad \text{for all } S \subseteq \{1..n\} \text{ with } 1 \in S, i \in S, i \ne 1
\end{aligned}
$$

> [!note]
> _S\{i} means the set S with city i removed. Fill order: by increasing |S|. d(j,i) = distance from j to i._

**(c) Analysis:**

- **(1) Subproblems:** `O(2ⁿ · n)`
- **(2) Fill time:** `O(2ⁿ · n²)`
- **(3) Return:** `min{ T({1..n}, i) + d(i,1) : 2 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

#### Flavor 2: "Subset Partitioning" (Minimum Cost to Partition into Groups)

**Concept:** _You don't care about order or endpoints — just split the universe into optimal subsets. Iterate over all submasks S' of S._

**(a) Subproblem:** T(S) = minimum cost to optimally partition the elements in set S into groups.

**(b) Recurrence:**

**Base Cases:**

$$
T(\emptyset) = 0
$$

**Recursive Step:**

$$
\begin{aligned}
T(S) &= \min_{\substack{S' \subseteq S \\ S' \ne \emptyset}} \{ T(S \setminus S') + \text{cost}(S') \} \\
     &\quad \text{for all non-empty } S \subseteq \{1..n\}
\end{aligned}
$$

> [!note]
> _The 3ⁿ runtime comes from iterating over all submasks of all masks. Each element is in S', in S\S', or not in S — three choices per element._

**(c) Analysis:**

- **(1) Subproblems:** `O(2ⁿ)`
- **(2) Fill time:** `O(3ⁿ)`
- **(3) Return:** `T({1..n})`
- **(4) Return time:** `O(1)`

### What to remember

- **Topologies**: 1D chain, 2D Grid, Knapsack, Interval (Pyramid), Tree, and Bitmask (Subsets).
- **Subproblem Definition is Key**: T(i) / T(i, j) must be written in English mapping exactly to the components of the desired end state.
- **Four required components**: (a) Subproblem, (b) Recurrence (with base cases & bounds), (c) Time/Space complexity analysis, (d) Return statement.
- **No Recursion Allowed**: Formulate iterative topological sorts, utilizing 1-based indexing, table storage, without modifying immutable input sets.

## Resources

### Books

This is the primary textbook for the course.

<BookCard
  title="Algorithms"
  author="Sanjoy Dasgupta, Christos Papadimitriou, and Umesh Vazirani"
  img={algsDpvImg}
  url="https://highered.mheducation.com/sites/0073523402/"
>
  <p>
    The accompanying text for the course. It provides clear, concise, and elegant explanations of Divide & Conquer and Dynamic Programming concepts.
  </p>
</BookCard>

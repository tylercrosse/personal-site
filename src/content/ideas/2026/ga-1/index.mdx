---
title: "Divide & Conquer + Dynamic Programming"
description: "Exam 1"
date: "2026-02-19"
# updated: '2026-10-20'
status: "in-progress"
type: "retro"
tags: ["algorithms", "computer-science", "MSCS"]
# category: ['projects']
draft: true
audience: "All"
media_subpath: "/ideas/ga-1/"
# parent: '2025/dl-retro'
image:
  # path: "hero-clipart-blume-vintage-kunst-1631264278ngu.png"
  # path: "hero-backprop.png"
  path: "hero2.jpg"
  alt: "Green ripples abstract art"
  # maxWidth: "800px"
hideCaption: true
---

import MasterTheoremViz from "../../../../components/ideas/ga-1/MasterTheoremViz.jsx";
import DPDagVisualizer from "../../../../components/ideas/ga-1/DPDagVisualizer.jsx";

This post captures my Exam 1 study notes for OMSCS Graduate Algorithms with two interactive tools I used to build intuition under time pressure.

## Divide & Conquer

Use this to map a recurrence to Master Theorem behavior and see which level dominates work as parameters change.

### Solution Format

The course encourages structuring problem-solving into distinct sections rather than diving straight into code. This approach builds a habit of thinking algorithmically and mathematically. _Note: Correctness is never assumed from the algorithm steps; it must be explicitly argued._

- **(a) Algorithm Description:** Explain _how_ your algorithm solves the problem using a plain-English narrative. You can use paragraphs or high-level bullet points, but **pseudocode is strictly forbidden**.
  - Avoid writing code disguised as words (e.g., translating a script line-by-line). Deeply nested bullet points are usually a red flag that you are doing this.
  - Walk through every major step, ending with the final return statement.
  - If you are adapting a known algorithm, explicitly highlight the modifications you made.
- **(b) Justification of Correctness:** Explain _why_ your algorithm works.
  - Write a narrative, informal justification (no formal mathematical or inductive proofs are required).
  - If you modified a known algorithm, you must explain why your specific tweaks are correct and successfully solve the problem.
- **(c) Runtime Analysis:** Analyze your algorithm using worst-case **Big-O notation**.
  - You can skip analyzing O(1) operations.
  - You may assert the standard runtime of unmodified "black-box" algorithms without extra proof.
  - If you modify a black box, you must justify how those changes impact the runtime—even if the overall Big-O doesn't change.
  - Always conclude with a single, fully simplified final runtime in Big-O notation.

---

### Guide to finding a D&C solution

Follow this workflow to brainstorm and write your solution:

1. **Identify the Pattern:** Determine if your problem maps to a standard algorithm.
   - _Sorted data_ usually points to Binary Search.
   - _Unsorted data_ usually points to Merge Sort or FastSelect.
   - _Polynomials, convolution, or multiplication_ usually point to Fast Fourier Transform (FFT). For integer multiplication specifically, Karatsuba's algorithm is a classic approach ($O(n^{\log_2 3})$).
2. **Define Modifications (If Any):** Decide if you can use the known algorithm "as is" or if it needs tweaking. If you tweak it, clearly outline what steps, inputs, or outputs are changing.
3. **Draft the Steps:** Write out the algorithm's execution in clear words. Make sure to define your base cases (if needed) and ensure your algorithm ultimately returns exactly what the prompt asks for.
4. **Draft the Proof of Correctness:** Write out your informal proof. To build a strong justification, answer questions like:
   - _Why is this specific black box suited for this input data?_
   - _Why did you make those specific modifications?_
   - _Why are we guaranteed that the problem space shrinks on each round?_
   - _Why are the base cases logically sound?_
   - _What is the logic behind branching left or right on each recursive call?_
5. **Calculate the Runtime:** Step through your algorithm to build your final worst-case Big-O analysis.

### Master Theorem

For some constants $a > 0$, $b > 1$, and $d \geq 0$,
where:
$a$ - number of subproblems
$b$ - is the factor by which the input size shrinks
$d$ - is the exponent of the work done at each level of recursion (so combining costs $O(n^d)$)

$$
T(n) = \underbrace{aT (n/b)}_{\text{recursive branching}} + \underbrace{O(n^d)}_{\text{local work (root)}}
$$

$$
T(n) =
\begin{cases}
\Theta(n^{\log_b(a)}) &\text{if } n^{\log_b(a)} > n^d \quad\text{ ``leaf heavy"} \\
\Theta(n^d \log(n)) &\text{if } n^{\log_b(a)} = n^d \quad\text{ ``balanced"}\\
\Theta(n^d) &\text{if } n^{\log_b(a)} < n^d \quad\text{ ``root heavy"} \\
\end{cases}
$$

- **Case 1 (Leaf-Heavy):** $n^{\log_b​(a)} > n^d$. The recursive branching explodes, meaning the vast majority of the work happens at the bottom of the tree. The leaves win, so the bound is strictly the number of leaves: $\Theta(n^{\log_b​(a)})$.

- **Case 2 (Perfectly Balanced):** $n^{\log_b​(a)} = n^d$. It is a tie. The local work at the root matches the work at the leaves, and the work across every internal level of the tree is identical. Because the work per level is constant, you just multiply the root work by the number of levels ($\log n$). The bound is: $\Theta(n^d\log n)$. _(Note: The "extended" Case 2 handles $f(n) = \Theta(n^{\log_b a} \log^k n)$, resulting in $\Theta(n^{\log_b a} \log^{k+1} n)$)._
- **Case 3 (Root-Heavy):** $n^{\log_b​(a)} < n^d$. The local work dwarfs the branching. The work shrinks geometrically as you go down the tree, meaning the total time is dominated by the massive chunk of work done at the very beginning. The root wins, so the bound is strictly the root work: $\Theta(n^d)$.

### Divide & Conquer Visualization

Drag the $a, b,$ and $d$ sliders below to see how the recursion tree shifts between the three Master Theorem cases.

<div class="viz-shell">
  <MasterTheoremViz client:visible />
</div>

### Work per level

1. **Number of nodes:** At level $k$, the tree has branched $k$ times, so there are $a^k$ nodes.
2. **Size of each subproblem:** The problem size $n$ has been divided by $b$ exactly $k$ times, making the input size for each node $n/b^k$.
3. **Work per node:** Since the local work is bounded by $O(\text{size}^d)$, the work at a single node on level $k$ is $(\frac{n}{b^k}​)^d$, which simplifies to $\frac{n^d}{b^{kd}}​$.

If you multiply the **number of nodes** by the **work per node**, you get the total work for the entire $k$-th level:

$$
a^k \times \frac{n^d​}{b^{kd}}
$$

Pull out the $n^d$ (which is the work at the root), and group the $k$ exponents together, and you get the formula for the total work done at the $k$-th level of the tree:

$$
O(n^d) \times \left(\frac{a}{b^d}\right)^k
$$

The Master Theorem uses $\log_b​(a)$ instead of just comparing $a$ to $b^d$. It is just a logarithmic algebraic rewrite of the exact same inequality!

If you take $a=b^d$ and take the $\log_b$​ of both sides, you get:

$$
\log_b​(a)=\log_b​(b^d)
$$

$$
\log_b​(a)=d
$$

So, comparing $\log_b​(a)$ to $d$ is mathematically identical to comparing the branching factor $a$ to the work-shrinkage factor $b^d$.

## Dynamic Programming

Use this to inspect how different DP families map to DAG shapes, transitions, and extraction paths.

### Solution Format

Every DP solution in this course requires four components:

**(a) Subproblem Definition.** Define T(i) or T(i,j) in words, built on a subset of the input (e.g., A[1..i]). May or may not require inclusion of the last element.

**(b) Recurrence.** Mathematical notation only — no code, no prose. A single definition covering all entries, with base cases and variable bounds.

**(c) Implementation Analysis:**

1. Number of subproblems in Big-O.
2. Runtime to fill table.
3. Where/how to extract the final answer.
4. Runtime of extraction.

_(Note on Extraction: Just finding the optimal numeric value is often not enough. If a problem asks for the optimal sequence or path, you must trace back through the table/DAG to reconstruct it. This typically takes $O(n)$ or time proportional to the path length.)_

_Key rules: No recursion/memoization. Inputs indexed from 1. Inputs are immutable. Tables store primitives only. Tables may start from index 0 or -1 for base cases._

### Problem-Solving Heuristics

**1. What is the topology?** Is the input a 1D array, a pair of strings, items with weights, an interval, a tree, or a set of elements?

**2. What are you optimizing?** Max/min value? Count of ways? Length of a subsequence?

**3. What constraint distinguishes the flavor?** Must be contiguous (Kadane) vs. no-adjacent (Robber) vs. any subsequence (LIS)? Match-based (LCS) vs. cost-based (Edit Dist)? Items used once (0/1) vs. unlimited (Unbounded)?

**4. Write the subproblem in words first.** This is the most important step. The recurrence follows naturally from a correct subproblem definition.

**5. Always define base cases.** Ensure every referenced table entry is well-defined. If T(i) references T(i-2), define T(0) and possibly T(-1).

**6. Provide bounds for all variables.** Every variable in the recurrence must have explicit bounds (e.g., "for 1 ≤ i ≤ n").

### Dynamic Programming Visualization

<div class="viz-shell">
  <DPDagVisualizer client:visible />
</div>

<style>
  {`
    /* Allow math blocks to scroll horizontally if they overflow */
    .katex-display {
      overflow-x: auto;
      overflow-y: hidden;
      padding-top: 0.5em;
      padding-bottom: 0.5em;
    }
    
    .viz-shell {

      grid-column: 1 / 4 !important;
      position: relative;
      z-index: 1;
      isolation: isolate;
      width: 100%;
      max-width: 1600px;
      margin: 1rem auto 2rem;
      overflow-x: auto;
    }
  `}
</style>

### Pattern A: Linear (1D Chain)

The topology is a 1D array. The flavor depends on how far back you look and what you accumulate.

#### Flavor 1: "Look-Back-One" (Contiguous / Kadane's Style)

**Concept:** _You must extend the immediately preceding subproblem, or start completely over. The current element must be included._

**(a) Subproblem:** T(i) = maximum sum of a contiguous subarray of A[1..i] which includes A[i].

**(b) Recurrence:**

**Base Cases:**

$$
T(1) = A[1]
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= \max( A[i],  T(i-1) + A[i] ) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _Interpretation: either start a new subarray at A[i], or extend the best subarray ending at A[i-1]._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max{ T(i) : 1 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

#### Flavor 2: "Look-Back-Two" (Skip / House Robber Style)

**Concept:** _Adjacent elements cannot both be selected. Decide whether to take the current element (skip previous) or leave it (keep previous optimal). The current element need not be included._

**(a) Subproblem:** T(i) = maximum sum obtainable from A[1..i] (A[i] may or may not be selected).

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0) &= 0 \\
T(1) &= A[1]
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= \max( T(i-1),  T(i-2) + A[i] ) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _T(i-1) = skip A[i]; T(i-2) + A[i] = take A[i] and skip A[i-1]._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `T(n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Look-Back-All" (Subsequence / LIS Style)

**Concept:** _The sequence need not be contiguous. Scan all previous valid subproblems to find the best predecessor. The current element must be included._

**(a) Subproblem:** T(i) = length of the longest increasing subsequence of A[1..i] which includes A[i].

**(b) Recurrence:**

**Base Cases:**

$$
T(1) = 1
$$

**Recursive Step:**

$$
\begin{aligned}
T(i) &= 1 + \max \big( \{0\} \cup \{ T(j) : \\
     &\quad 1 \le j < i,\; A[j] < A[i] \} \big) \\
     &\quad \text{for } 2 \le i \le n
\end{aligned}
$$

> [!note]
> _If no j satisfies A[j] < A[i], the max is taken over {0} (set containing zero), so T(i) = 1._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n²)`
- **(3) Return:** `max{ T(i) : 1 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

### Pattern B: Grid (2D / Strings)

The topology is the (i-1, j), (i, j-1), (i-1, j-1) neighborhood. The flavor depends on whether you match elements or accumulate path costs.

#### Flavor 1: "Match or Drop" (Longest Common Subsequence)

**Concept:** _If elements match, gain 1 and consume both. If not, drop one element from either sequence and take the best._

**(a) Subproblem:** T(i,j) = length of the LCS of A[1..i] and B[1..j].

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,j) &= 0 \quad \text{for } 0 \le j \le m \\
T(i,0) &= 0 \quad \text{for } 0 \le i \le n
\end{align*}
$$

**Recursive Step:**

$$
T(i,j) =
\begin{aligned}
&\begin{cases}
T(i-1,j-1) + 1 & \text{if } A[i] = B[j] \\
\max( T(i-1,j),  T(i,j-1) ) & \text{if } A[i] \ne B[j]
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 1 \le j \le m
\end{aligned}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Penalty Cost" (Edit Distance)

**Concept:** _Transform A into B. Every mismatch incurs a cost; take the minimum of substitution, deletion, or insertion._

**(a) Subproblem:** T(i,j) = minimum edit distance to transform A[1..i] into B[1..j].

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,j) &= j \quad \text{for } 0 \le j \le m \quad (\text{insert } j \text{ characters}) \\
T(i,0) &= i \quad \text{for } 0 \le i \le n \quad (\text{delete } i \text{ characters})
\end{align*}
$$

**Recursive Step:**

$$
T(i,j) =
\begin{cases}
T(i-1,j-1) & \text{if } A[i] = B[j] \\
1 + \min\big( T(i-1,j-1), \\
\quad T(i-1,j), T(i,j-1) \big) & \text{if } A[i] \ne B[j]
\end{cases}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Path Accumulation" (Min Path Sum)

**Concept:** _Move through a physical grid accumulating weights. No matching — just movement constraints (right or down)._

**(a) Subproblem:** T(i,j) = minimum cost to reach cell (i,j) from cell (1,1).

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(1,1) &= C[1][1] \\
T(i,1) &= T(i-1,1) + C[i][1] \quad \text{for } 2 \le i \le n \\
T(1,j) &= T(1,j-1) + C[1][j] \quad \text{for } 2 \le j \le m
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= C[i][j] + \min( T(i-1,j), T(i,j-1) ) \\
       &\quad \text{for } 2 \le i \le n, 2 \le j \le m
\end{aligned}
$$

**(c) Analysis:**

- **(1) Subproblems:** `O(n·m)`
- **(2) Fill time:** `O(n·m)`
- **(3) Return:** `T(n,m)`
- **(4) Return time:** `O(1)`

---

### Pattern C: Knapsack

The topology involves jumping leftwards across a capacity dimension. The flavor changes based on whether items are unique, reusable, or you are counting combinations.

#### Flavor 1: "Take It or Leave It" (0/1 Knapsack)

**Concept:** _Each item can only be used once. You transition from the previous row (i-1)._

**(a) Subproblem:** T(i,w) = maximum value achievable using items from {1..i} with capacity w.

**(b) Recurrence:**

**Base Cases:**

$$
T(0,w) = 0 \quad \text{for } 0 \le w \le W
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,w) &= \begin{cases}
T(i-1,w) & \text{if } w_i > w \\
\max( T(i-1,w),  T(i-1, w-w_i) + v_i ) & \text{if } w_i \le w
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 0 \le w \le W
\end{aligned}
$$

> [!note]
> _wᵢ and vᵢ are the weight and value of item i._

**(c) Analysis:**

- **(1) Subproblems:** `O(n·W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(n,W)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Infinite Reuse" (Unbounded Knapsack / Min Coin Change)

**Concept:** _If you take an item, you can take it again. You transition from the current row (i), not (i-1). Shown here as Minimum Coin Change._

**(a) Subproblem:** T(j) = minimum number of coins needed to make change for amount j, using coins from the given denominations.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0) &= 0 \\
T(j) &= \infty \quad \text{if no coin } \le j
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(j) &= 1 + \min_{ \substack{1 \le i \le n\\c_i \le j} } \{ T(j - c_i) \} \\
     &\quad \text{for } 1 \le j \le W
\end{aligned}
$$

> [!note]
> _Can also be written as 2D: T(i,w) = min( T(i-1,w), T(i, w-cᵢ) + 1 ), where row i means "using coins 1..i" and staying in row i allows reuse._

**(c) Analysis:**

- **(1) Subproblems:** `O(W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(W)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "Counting Combinations" (Subset Sum / Coin Change 2)

**Concept:** _You are not maximizing value — you are summing all possible ways to reach a state. Replace max with +._

**(a) Subproblem:** T(i,w) = number of ways to form amount w using coins from {1..i}.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(0,0) &= 1 \\
T(0,w) &= 0 \quad \text{for } 1 \le w \le W
\end{align*}
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,w) &= \begin{cases}
T(i-1,w) & \text{if } c_i > w \\
T(i-1,w) + T(i, w-c_i) & \text{if } c_i \le w
\end{cases} \\
&\quad \text{for } 1 \le i \le n, 0 \le w \le W
\end{aligned}
$$

> [!note]
> _Staying in row i (for the cᵢ ≤ w case) allows reuse of coin i. Moving to row i-1 only would give 0/1 counting._

**(c) Analysis:**

- **(1) Subproblems:** `O(n·W)`
- **(2) Fill time:** `O(n·W)`
- **(3) Return:** `T(n,W)`
- **(4) Return time:** `O(1)`

---

### Pattern D: Interval (Pyramid)

The topology always merges sub-intervals. The flavor depends on whether you split at an arbitrary k, shrink from edges, or pivot on the last action.

#### Flavor 1: "The K-Split" (Matrix Chain Multiplication / Optimal BST)

**Concept:** _The cost of interval (i,j) depends on splitting it into (i,k) and (k+1,j) plus the cost to merge._

**(a) Subproblem:** T(i,j) = minimum cost to multiply matrices Aᵢ through Aⱼ. (Matrix Aᵢ has dimensions p[i-1] × p[i].)

**(b) Recurrence:**

**Base Cases:**

$$
T(i,i) = 0 \quad \text{for } 1 \le i \le n
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \min_{ i \le k \le j-1} \{ T(i,k) + T(k+1,j) + p[i-1] \cdot p[k] \cdot p[j] \} \\
       &\quad \text{for } 1 \le i < j \le n
\end{aligned}
$$

> [!note]
> _Fill order: by increasing interval length ℓ = j - i, from ℓ=1 up to ℓ=n-1._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n³)`
- **(3) Return:** `T(1,n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Shrink from Edges" (Longest Palindromic Subsequence)

**Concept:** _No k-loop needed. Compare the two outermost elements. If they match, the interval shrinks by 2. If not, shrink by 1 from either side._

**(a) Subproblem:** T(i,j) = length of the longest palindromic subsequence of A[i..j].

**(b) Recurrence:**

**Base Cases:**

$$
T(i,i) = 1 \quad \text{for } 1 \le i \le n
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \begin{cases}
T(i+1,j-1) + 2 & \text{if } A[i] = A[j] \\
\max( T(i+1,j),  T(i,j-1) ) & \text{if } A[i] \ne A[j]
\end{cases} \\
&\quad \text{for } 1 \le i < j \le n
\end{aligned}
$$

> [!note]
> _Base case T(i,i+1): if A[i]=A[i+1] then 2, else 1. This is handled by the recurrence if you define T(i,i-1)=0 for empty intervals._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n²)`
- **(3) Return:** `T(1,n)`
- **(4) Return time:** `O(1)`

---

#### Flavor 3: "The Last Action" (Burst Balloons)

**Concept:** _Instead of the first split, think about k as the last balloon popped in interval (i,j). This makes left and right subproblems independent._

**(a) Subproblem:** T(i,j) = maximum coins from bursting all balloons in the open interval (i,j), where i and j are unpopped boundary balloons.

**(b) Recurrence:**

**Base Cases:**

$$
T(i,j) = 0 \quad \text{if } j = i+1 \quad (\text{no balloons between})
$$

**Recursive Step:**

$$
\begin{aligned}
T(i,j) &= \max_{i < k < j} \{ T(i,k) + T(k,j) + A[i] \cdot A[k] \cdot A[j]\} \\
       &\quad \text{for } 0 \le i < j \le n+1
\end{aligned}
$$

> [!note]
> _Boundaries A[0] and A[n+1] are sentinel values = 1. The key insight: choosing k last means the left/right subproblems don't interfere._

**(c) Analysis:**

- **(1) Subproblems:** `O(n²)`
- **(2) Fill time:** `O(n³)`
- **(3) Return:** `T(0, n+1)`
- **(4) Return time:** `O(1)`

---

### Pattern E: Tree DP

Tree DP requires defining multiple states per node to handle inclusion/exclusion constraints. Fill order is post-order (leaves first, root last).

#### Flavor 1: "Independent Set" (Max Weight Independent Set / House Robber III)

**Concept:** _You cannot select a node and its direct children. Two states per node: exclude or include._

**(a) Subproblem:** T(u,0) = max weight of an independent set in the subtree rooted at u, excluding u. T(u,1) = same, including u.

**(b) Recurrence:**

**Base Cases:**

$$
\begin{align*}
T(u,0) &= 0 \\
T(u,1) &= w(u)
\end{align*}
\quad \text{for leaf node } u
$$

**Recursive Step:**

$$
\begin{align*}
T(u,0) &= \sum \max( T(v,0), T(v,1) ) \\
       &\quad \text{over all children } v \text{ of } u \\
T(u,1) &= w(u) + \sum T(v,0) \\
       &\quad \text{over all children } v \text{ of } u
\end{align*}
$$

> [!note]
> _When u is excluded, each child is free to be included or not. When u is included, all children must be excluded._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)  (2 states per node)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max( T(root,0), T(root,1) )`
- **(4) Return time:** `O(1)`

---

#### Flavor 2: "Path Tracking" (Diameter of a Tree)

**Concept:** _The longest path may arch over a node. T(u) tracks the longest straight path down from u; a secondary equation tracks the arch._

**(a) Subproblem:** T(u) = length of the longest path starting at u and going downward into the subtree of u.

**(b) Recurrence:**

**Base Cases:**

$$
T(u) = 1 \quad \text{for leaf node } u
$$

**Recursive Step:**

$$
\begin{aligned}
T(u) &= 1 + \max \{ T(v) : v \text{ is a child of } u \} \\
     &\quad (\text{longest arm in nodes})
\end{aligned}
$$

To extract the exact answer for the diameter:

$$
\begin{aligned}
&\text{Diameter through } u = T(v_1) + T(v_2) + 1 \\
&\quad (\text{where } v_1, v_2 \text{ are children with largest } T)
\end{aligned}
$$

$$
\text{Answer} =
\begin{cases}
\max_u \{ \text{diameter through } u \} - 1 & (\text{if asking for edges}) \\
\max_u \{ \text{diameter through } u \} & (\text{if asking for nodes})
\end{cases}
$$

> [!note]
> _If u has ≤1 child, diameter through u is just T(u). Track the global max during the fill pass._

**(c) Analysis:**

- **(1) Subproblems:** `O(n)`
- **(2) Fill time:** `O(n)`
- **(3) Return:** `max over all u of (top two T(child) values summed)`
- **(4) Return time:** `O(n)`

---

### Pattern F: Bitmask (Subset DP)

Bitmasks track which elements have been visited/used. Subsets are encoded as integers where bit i indicates element i is in the set. The flavor changes based on whether you care about the ending node or just the groups formed.

#### Flavor 1: "Path Building" (Traveling Salesperson Problem)

**Concept:** _You need to know which cities S you have visited AND which city i you are currently at, so you can extend to the next city j._

**(a) Subproblem:** T(S,i) = minimum cost to visit exactly the cities in set S, starting from city 1 and ending at city i, where i ∈ S.

**(b) Recurrence:**

**Base Cases:**

$$
T(\{1\}, 1) = 0
$$

**Recursive Step:**

$$
\begin{aligned}
T(S, i) &= \min_{j \in S\setminus\{i\}} \{ T(S\setminus\{i\}, j) + d(j,i) \} \\
        &\quad \text{for all } S \subseteq \{1..n\} \text{ with } 1 \in S, i \in S, i \ne 1
\end{aligned}
$$

> [!note]
> _S\{i} means the set S with city i removed. Fill order: by increasing |S|. d(j,i) = distance from j to i._

**(c) Analysis:**

- **(1) Subproblems:** `O(2ⁿ · n)`
- **(2) Fill time:** `O(2ⁿ · n²)`
- **(3) Return:** `min{ T({1..n}, i) + d(i,1) : 2 ≤ i ≤ n }`
- **(4) Return time:** `O(n)`

---

#### Flavor 2: "Subset Partitioning" (Minimum Cost to Partition into Groups)

**Concept:** _You don't care about order or endpoints — just split the universe into optimal subsets. Iterate over all submasks S' of S._

**(a) Subproblem:** T(S) = minimum cost to optimally partition the elements in set S into groups.

**(b) Recurrence:**

**Base Cases:**

$$
T(\emptyset) = 0
$$

**Recursive Step:**

$$
\begin{aligned}
T(S) &= \min_{\substack{S' \subseteq S \\ S' \ne \emptyset}} \{ T(S \setminus S') + \text{cost}(S') \} \\
     &\quad \text{for all non-empty } S \subseteq \{1..n\}
\end{aligned}
$$

> [!note]
> _The 3ⁿ runtime comes from iterating over all submasks of all masks. Each element is in S', in S\S', or not in S — three choices per element._

**(c) Analysis:**

- **(1) Subproblems:** `O(2ⁿ)`
- **(2) Fill time:** `O(3ⁿ)`
- **(3) Return:** `T({1..n})`
- **(4) Return time:** `O(1)`

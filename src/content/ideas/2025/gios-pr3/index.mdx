---
title: 'IPC in Action: Building a High-Performance Proxy & Cache'
description: 'A dive into inter-process communication, shared memory, and synchronization in C, based on a project from my graduate Operating Systems course.'
date: '2025-06-24'
status: 'complete'
type: 'project'
tags: ['GIOS', 'operating-systems', 'c', 'IPC', 'socket-programming']
category: ['projects']
draft: false
audience: 'All'
media_subpath: "/ideas/gios-pr3/"
image:
  path: "./moebius-fly-dawn.png"
  alt: 'Moebius Fly Dawn by Jean Giraud'
---

import { Image } from "astro:assets";
import BookCard from "../../../../components/BookCard.astro";
import Figure from "../../../../components/Figure.astro";

import osTepImg from "../../../books/os-tep.jpg";
import csAppImg from "../../../books/cs-app.jpg";
import cLangImg from "../../../books/c-lang.jpg";
import beejGuidesImg from "../../../books/beej-network.jpg";
import linuxInterfaceImg from "../../../books/linux-interface.png";

import ipcImg from "./ipc.png";
import stringCommImg from "./string-communication.jpg";

## Introduction: When a Program Needs to Talk to Itself

In my previous project, I built a [multithreaded file server](/ideas/2025/gios-pr1/) that could handle many clients at once. All the work happened within a single program, a unified team of threads sharing the same memory. But what happens when you need to separate concerns more strictly? When one part of your system should be a specialized service, and another part its client?

This was the challenge for my next project in Georgia Tech's OS course: to build a system of two distinct programs—a **proxy server** and a **cache server**—that had to communicate and cooperate to serve files. This wasn't about threads anymore; it was about full-fledged processes.

This forced me to dive into one of the most fundamental topics in operating systems: **Inter-Process Communication (IPC)**. The project was to design a system where a proxy fetches files for a client, but first checks with a separate cache process to see if it already has a copy. If it did, the file data had to be passed from the cache to the proxy, and then to the client, as fast as possible. This post explores the journey of building that system, and the powerful, tricky, and essential world of IPC.

## The Architecture: A Separation of Concerns

The goal was to extend a simple web server with a proxy and a cache. This is a classic pattern used everywhere on the web to improve performance and scalability.

1.  **Proxy Server**: The public-facing intermediary. It takes requests from clients, but instead of getting the files itself, it turns around and asks the cache server. If the cache doesn't have it, *then* the proxy gets it from the original web server (and tells the cache to store it). It handles all the network logic.
2.  **Cache Server**: The specialized backend. Its only job is to store and retrieve files in memory. It doesn't talk to the outside world; it only talks to the proxy.

<Figure
  src={ipcImg}
  alt="A diagram showing a client talking to a proxy, which in turn communicates with a cache server via IPC and a web server via HTTP."
  caption="The proxy acts as a middleman, consulting the cache via IPC before fetching from the source."
/>

The key question is: how do these two separate processes, which by default know nothing about each other, communicate?

## A Primer on Inter-Process Communication (IPC)

Modern operating systems are built on a bedrock principle: **process isolation**. Each process gets its own private virtual address space, its own chunk of memory that no other process can touch. This is a crucial security and stability feature. Without it, a bug in your web browser could crash your entire operating system.

But this isolation creates a problem: what if processes *need* to cooperate? That's where IPC comes in. The OS provides a set of controlled "doorways" through the walls of process isolation. These mechanisms are all mediated by the kernel, ensuring that communication happens in a structured and safe way.

Some common IPC mechanisms include:

-   **Pipes:** A simple one-way communication channel. What you write in one end, you read from the other.
-   **Sockets:** The same mechanism used for network communication can be used for IPC on the same machine (via Unix domain sockets). It's like networking without the network.
-   **Message Queues:** A structured way to send small "messages" between processes, like a system-wide mailbox.
-   **Shared Memory:** The fastest, most powerful, and most dangerous method. The OS maps the same region of physical RAM into the virtual address space of multiple processes, allowing them to read and write to the same memory location directly.

For this project, the goal was maximum performance, which pointed to a hybrid approach: **Shared Memory** for the heavy lifting (transferring file data) and a **Message Queue** for coordination.

## Shared Memory: The High-Speed Data Link

Shared memory is the IPC equivalent of teleportation. Instead of packaging data, handing it to the kernel (a system call), and having the kernel deliver it to another process (another system call), shared memory bypasses the kernel entirely for the data transfer itself.

Once set up, a write to a memory address in process A is *instantly* visible to process B at a corresponding memory address. This is incredibly fast because there's no copying. Both processes are looking at the *exact same bytes* in physical RAM.

But this power comes with immense responsibility.

-   **No Built-in Synchronization:** Shared memory is just a raw slab of bytes. If the proxy is reading from a segment of memory while the cache is still writing to it, the proxy will read corrupted, nonsensical data. There are no traffic lights or stop signs; it's a free-for-all.
-   **Life After Death:** IPC resources like shared memory segments exist at the OS level, outside of any single process. If your program crashes without cleaning up, that shared memory segment can be left orphaned, leaking system resources until the next reboot.

## Message Queues: The Command Channel

If shared memory is the bulk cargo freighter, the message queue is the walkie-talkie used to coordinate the loading and unloading. We needed a way for the proxy to send commands to the cache, like "Do you have `/images/cat.jpg`?" or "Please store this file I just downloaded."

A message queue is perfect for this. It allows for sending small, structured messages between processes. The proxy could package up a request into a message, send it to the queue, and the cache, which would be listening on that queue, would receive it and know what to do. This neatly separates the control signals from the data itself. The messages contained metadata about the files, while the shared memory was reserved for the file contents.

## Synchronization and Cleanup: Tying It Together

With two powerful but unruly mechanisms in play, the biggest challenges were synchronization and resource management.

### Preventing Chaos with Semaphores

To prevent the proxy and cache from writing over each other's data in the shared memory, we needed a synchronization primitive that works across processes. While mutexes are great for threads, **semaphores** are a classic solution for synchronizing separate processes.

A semaphore acts as a gatekeeper for a resource. Before accessing the shared memory, a process must acquire the semaphore. If the semaphore is already taken, the process will block (sleep) until it's released. This ensures that only one process can be operating on the shared data at any given time, preventing data races and corruption. It's the traffic light system we needed for our shared memory highway.

### Graceful Exits with Signal Handlers

The "orphaned resource" problem is a classic bug in systems programming. To solve it, I implemented **signal handlers**. A signal is a notification sent to a process by the OS about an event. By catching signals like `SIGINT` (from Ctrl-C) or `SIGTERM` (from a `kill` command), the program can execute a special cleanup function before it terminates. This function's job was to meticulously detach from and remove the shared memory segments and message queues, ensuring the system remained clean no matter how the processes exited.

## Conclusion: Building Cooperative Systems

This project was a fantastic lesson in the trade-offs of system design. While building a single, monolithic program is often simpler, splitting a system into specialized processes can lead to a more modular, scalable, and maintainable architecture.

The key takeaways were:

-   **IPC is a spectrum:** There's a tool for every job, from slow-but-simple pipes to fast-but-complex shared memory. The right choice depends entirely on the problem's requirements.
-   **Synchronization is non-negotiable:** With great power comes great responsibility. Using high-performance IPC like shared memory *requires* robust, process-aware synchronization to prevent chaos.
-   **Resource management is paramount:** Processes are mortal, but OS-level resources can be eternal. Writing code that cleans up after itself is a hallmark of a reliable system.

While a production cache might use more advanced techniques, the fundamental principles are the same. This project provided a tangible, low-level understanding of how independent programs can be orchestrated to build a cooperative, high-performance system.

## Additional resources

These books and guides were extremely helpful for understanding the concepts and APIs for IPC in C.

<BookCard
  title="The C Programming Language"
  author="Brian W. Kernighan and Dennis M. Ritchie"
  img={cLangImg}
  url="https://www.google.com/books/edition/The_C_Programming_Language/OpJ_0zpF7jIC"
>
    <p>
        The definitive book on C, written by its creators. Essential for mastering the language itself.
    </p>
</BookCard>

<BookCard
  title="Beej's Guides to C, Network Programming, and IPC"
  author="Brian 'Beej' Hall"
  img={beejGuidesImg}
  url="https://beej.us/guide/"
>
    <p>
        An invaluable, practical, and free resource. The IPC guide was a lifesaver for this project, providing clear, working examples for shared memory and semaphores.
    </p>
</BookCard>

<BookCard
  title="The Linux Programming Interface"
  author="Michael Kerrisk"
  img={linuxInterfaceImg}
  url="https://man7.org/tlpi/"
>
    <p>
        The encyclopedic guide to the Linux and UNIX system programming interface. The chapters on System V IPC and POSIX IPC are incredibly detailed and authoritative.
    </p>
</BookCard>

<BookCard
  title="Operating Systems: Three Easy Pieces"
  author="Remzi H. Arpaci-Dusseau and Andrea C. Arpaci-Dusseau"
  img={osTepImg}
  url="https://pages.cs.wisc.edu/~remzi/OSTEP/"
>
  <p>
    This is the main book I used to supplement the lectures. Its chapters on concurrency and persistence provide the conceptual backbone for understanding why IPC is necessary and how it works.
  </p>
</BookCard>

> [!info] A Note on Code Availability
> In accordance with Georgia Tech's academic integrity policy and the license for course materials, the source code for this project is kept in a private repository. I believe passionately in sharing knowledge, but I also firmly respect the university's policies. This document follows [Dean Joyner's advice on sharing projects](https://www.reddit.com/r/OMSCS/comments/zwdwns/comment/j1udv6w/).
>
> I would be delighted to discuss the implementation details, architecture, or specific code sections in an interview. Please feel free to reach out to request private access to the repository.
